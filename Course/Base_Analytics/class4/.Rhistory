insurance_data<- read.csv("D:/work/Shanu/ATI/Base_Analytics/class4/insurance.csv")
#Check the Structure of data
str(insurance_data)
#Check the summary of data, if any missing values NA
summary(insurance_data)
#Check first few rows
head(insurance_data)
#Step2: Data Exploration
library(ggplot2)
ggplot(insurance_data, aes(x =charges)) +
geom_histogram(binwidth = 10000)
#Is it more for smoker
ggplot(insurance_data, aes(x =charges, fill=smoker)) +
geom_histogram(binwidth = 10000)
ggplot(insurance_data, aes(x=smoker, y =charges)) +
geom_boxplot()
ggplot(insurance_data, aes(x=sex, y =charges)) +
geom_boxplot()
#Is it more for region
ggplot(insurance_data, aes(x=region, y =charges)) +
geom_boxplot()
#Is it more for more kids
ggplot(insurance_data, aes(x= as.factor(children), y =charges)) +   geom_boxplot()
#is it older people have more expense?
ggplot(insurance_data, aes(x=age,y =charges)) +   geom_point()
#is it older people have more expense? and differs in smoker
ggplot(insurance_data, aes(x=age,y =charges, color=smoker)) +   geom_point()
#is it obess people have more expense?
ggplot(insurance_data, aes(x=bmi,y =charges)) +   geom_point()
#is it obess people have more expense? and differs in smoker
ggplot(insurance_data, aes(x=bmi,y =charges, color=smoker)) +   geom_point()
table(insurance_data$region)
table(insurance_data$sex)
cor(insurance_data[c("age", "bmi", "children", "charges")])
ins_model <- lm(charges ~ age + children + bmi + sex +
smoker + region, data = insurance_data)
summary(ins_model )
#step1: Reading the Data
default_data<- read.csv("D:/work/Shanu/ATI/Base_Analytics/class5/Default.csv")
View(default_data)
default_data<- read.csv("D:/work/Shanu/ATI/Base_Analytics/class5/Default.csv")
#Check the Structure of data
str(default_data)
#Check the summary of data, if any missing values NA
summary(default_data)
#Check first few rows
head(default_data)
colnames(default_data)
library(ggplot2)
ggplot(default_data, aes(x=balance, y = income, color=default)) +
geom_point()
ggplot(default_data, aes(x=default, y =balance)) +
geom_boxplot()
ggplot(default_data, aes(x=default, y =income)) +
geom_boxplot()
table(default_data$student, default_data$default)
library(dplyr)
train_data <- default_data %>% sample_frac(.75)
#anti_join delete the data if present in other
test_data  <- anti_join(default_data, train_data)
log_model <- glm(default ~ balance, family="binomial",
data = train_data)
summary(log_model)
exp(5.718e-03 )
test_data$predicted_Prob <- predict(log_model, test_data,
type="response")
test_data$predicted_default <-ifelse(test_data$predicted_Prob > 0.5,
"Yes", "No")
table(test_data$default, test_data$predicted_default)
table(test_data$default)
table(test_data$predicted_default)
table(test_data$default, test_data$predicted_default)
(2398+20)/(2398+64+18+20)
2398/(2398+64)
2398/(2398+18)
20/(18+20)
20/(64+20)
cm = as.matrix(table(Actual = test_data$default,
Predicted =test_data$predicted_default)) # create the confusion matrix
cm
diag(cm)
apply(cm, 1, sum)
apply(cm, 2, sum)
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
p
q
recall= rowsums / n # distribution of instances over the actual classes
precision = colsums / n # distribution of instances over the predicted classes
recall
accuracy = sum(diag) / n
precision = diag / colsums
precision
recall = diag / rowsums
recall
seq(0.1,0.9,0.1)
prediction_score<-NULL
cutoffs <- seq(0.1,0.9,0.1)
for (i in seq(along = cutoffs)){
train_data$predicted_Prob <- predict(log_model, train_data,type="response")
train_data$predicted_default <-ifelse(train_data$predicted_Prob > cutoffs[i], "Yes", "No")
cm = as.matrix(table(Actual = train_data$default, Predicted = train_data$predicted_default)) # create the confusion matrix
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n
precision = diag / colsums
recall = diag / rowsums
f1= 2 * precision * recall / (precision + recall)
temp_prediction_score= data.frame(precision, recall, f1 )
temp_prediction_score$Threshold<-cutoffs[i]
temp_prediction_score$default= row.names(temp_prediction_score)
prediction_score<- rbind(prediction_score,temp_prediction_score)
}
library(ggplot2)
ggplot(prediction_score[prediction_score$default=="Yes",], aes(x=Threshold, y = f1)) +
geom_point()
caret::confusionMatrix(test_data$default,
as.factor(test_data$predicted_default),
positive="Yes", mode="everything")
summay_log_model<-caret::confusionMatrix(test_data$default,
as.factor(test_data$predicted_default),
positive="Yes", mode="everything")
summay_log_model<-caret::confusionMatrix(test_data$default,
as.factor(test_data$predicted_default),
positive="Yes", mode="everything")
View(summay_log_model)
str(summary_log_model)
summary_log_model<-caret::confusionMatrix(test_data$default,
as.factor(test_data$predicted_default),
positive="Yes", mode="everything")
str(summary_log_model)
summary_log_model$byClass
#read the Adversting Data
adversting_data<- read.csv("D:/work/Shanu/ATI/Base_Analytics/class4/Advertising.csv")
#Check the Structure of data
str(adversting_data)
#Check the summary of data, if any missing values NA
summary(adversting_data)
#Check first few rows
head(adversting_data)
reg_model<- lm(sales~ TV+radio+newspaper+TV*radio+radio*newspaper+
TV*newspaper, data=adversting_data)
summary(reg_model)
