house_data<- read.csv("D:\\work\\Shanu\\ATI\\Base_Analytics\\class4\\Regression-Analysis-Data.csv")
install.packages("Hmisc")
library(Hmisc)
describe(house_data)
#Missing value Treatment
titanic_data<- read.csv("D:/work/Shanu/ATI/Base_Analytics/class5/train.csv")
summary(titanic_data)
View(titanic_data)
colsum(is.na(titanic_data))
colSums(is.na(titanic_data))
View(titanic_data)
colSums(is.null(titanic_data))
#Missing value Treatment
titanic_data<- read.csv("D:/work/Shanu/ATI/Base_Analytics/class5/train.csv")
colSums(is.null(titanic_data))
is.null(titanic_data$PassengerId)
is.null(titanic_data)
is.na(titanic_data)
unique(titanic_data$Embarked)
unique(titanic_data$Cabin)
unique(titanic_data$Ticket)
#Missing value Treatment
titanic_data<- read.csv("D:/work/Shanu/ATI/Base_Analytics/class5/train.csv", stringsAsFactors = FALSE)
summary(titanic_data)
colSums(is.na(titanic_data))
unique(titanic_data$Cabin)
colSums(titanic_data[titanic_data==""])
colSums(titanic_data[titanic_data=="",])
aapply(titanic_data,2, function(x) sum(is.na(x)))
apply(titanic_data,2, function(x) sum(is.na(x)))
apply(titanic_data,2, function(x) sum(x==""))
apply(titanic_data,2, function(x) sum(is.na(x))
)
apply(titanic_data,2, function(x) sum(x==NULL))
apply(titanic_data,2, function(x) sum(x==""))
#To count missing values in each column
colSums(is.na(titanic_data))/nrow(titanic_data)
apply(titanic_data,2, function(x) sum(x=="")/length(x))
# Create the function.
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
# Create the vector with numbers.
v <- c(2,1,2,3,1,2,3,4,1,5,5,3,2,3)
# Calculate the mode using the user function.
result <- getmode(v)
print(result)
Mode <- function(x){
a = table(x) # x is a vector
return(a[which.max(a)])
}
# Create the vector with numbers.
v <- c(2,1,2,3,1,2,3,4,1,5,5,3,2,3)
# Calculate the mode using the user function.
result <- Mode (v)
print(result)
# Create the function.
Mode <- function(x){
a = table(x) # x is a vector
return(a[which.max(a)][1])
}
# Create the vector with numbers.
v <- c(2,1,2,3,1,2,3,4,1,5,5,3,2,3)
# Calculate the mode using the user function.
result <- Mode (v)
print(result)
Mode (v)
x=v
a = table(x)
a[which.max(a)]
a
names(table(a))[table(a)==max(table(a))]
names(table(a)
)
names(table(x))[table(x)==max(table(x))]
a = table(x) # x is a vector
names(a)[max(a)]
a
names(a)
names(a)[which.max(a)]
Mode(titanic_data$Embarked)
Mode <- function(x){
a = table(x) # x is a vector
return(names(a)[which.max(a)])
}
Mode(titanic_data$Embarked)
#replace NA value in age column with mean age
titanic_data[titanic_data$Embarked, 'Embarked'] = Mode(titanic_data$Embarked)
#Imputing missing values using mice
mice_imputes = mice(titanic_data, m=5, maxit = 40)
library(mice)
install.packages("mice")
library(mice)
#Imputing missing values using mice
mice_imputes = mice(titanic_data, m=5, maxit = 40)
View(mice_imputes)
remove_outliers <- function(x, na.rm = TRUE, ...) {
qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
H <- 1.5 * IQR(x, na.rm = na.rm)
y <- x
y[x < (qnt[1] - H)] <- NA
y[x > (qnt[2] + H)] <- NA
y
}
summary(remove_outliers(house_data$House_Price))
apply(house_data, 2, function(x) summary(remove_outliers(x)))
select_if(house_data,is.numeric)
library(dplyr)
select_if(house_data,is.numeric)
colnames(select_if(house_data,is.numeric))
apply(house_data[,numeric_columns], 2, function(x) summary(remove_outliers(x)))
numeric_columns= colnames(select_if(house_data,is.numeric))
apply(house_data[,numeric_columns], 2, function(x) summary(remove_outliers(x)))
apply(house_data[,numeric_columns], 2, function(x) sum(is.na(remove_outliers(x))))
outlier(house_data$House_Price)
install.packages("outliers")
library(outliers)
outlier(house_data$House_Price)
for( col in numeric_columns)
{
house_data[,col]<- remove_outliers(house_data[,col])
}
View(house_data)
#To remove all rows contains NA
house_data[complete.cases( house_data), ]
#To remove all rows contains NA
nrow(house_data[complete.cases( house_data), ])
#To remove all rows contains NA
nrow(house_data[complete.cases( house_data), ])/ nrow(house_data)
#Clustering of flowers
library(datasets)
head(iris)
#--------------------------------------------------------------------------------------
#Data Exploration
library(ggplot2)
ggplot(iris, aes(x=Petal.Length, y=Petal.Width, color = Species)) + geom_point()
#----------------------------------------------------------------------------------------
#Divide into train and test
library(dplyr)
train_data <- iris %>% sample_frac(.75)
#anti_join delete the data if present in other
test_data  <- anti_join(iris, train_data)
#------------------------------------------------------------------------------
#Scaling of Data
scaled_train_data<- train_data
scaled_test_data<- test_data
for(col in c("Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width" ))
{
scaled_train_data[,col]= (train_data[,col]- mean(train_data[,col]))/ sd(train_data[,col])
scaled_test_data[,col]= (test_data[,col]- mean(train_data[,col]))/ sd(train_data[,col])
}
#------------------------------------------------------
set.seed(20)
irisCluster <- kmeans( scaled_train_data[, 3:4], 3, nstart = 20,method="euclidean")
irisCluster
Kmeans(scaled_train_data[, 3:4], 3, nstart = 20,method="euclidean")
library(datasets)
head(iris)
library(datasets)
head(iris)
library(ggplot2)
ggplot(iris, aes(x=Petal.Length, y=Petal.Width, color = Species)) + geom_point()
ggplot(iris, aes(x=Petal.Length, y=Petal.Width,
color = Species)) + geom_point(size=10)
col="Sepal.Width"
train_data[,col]
library(dplyr)
train_data <- iris %>% sample_frac(.75)
#anti_join delete the data if present in other
test_data  <- anti_join(iris, train_data)
scaled_train_data<- train_data
scaled_test_data<- test_data
train_data[,col]
mean(train_data[,col])
sd(train_data[,col])
(train_data[,col]- mean(train_data[,col]))/ sd(train_data[,col])
colnames(scaled_train_data)
scaled_train_data<- train_data
scaled_test_data<- test_data
for(col in c("Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width" ))
{
scaled_train_data[,col]= (train_data[,col]- mean(train_data[,col]))/ sd(train_data[,col])
scaled_test_data[,col]= (test_data[,col]- mean(train_data[,col]))/ sd(train_data[,col])
}
View(scaled_train_data)
View(train_data)
scaled_train_data[, 3:4]
set.seed(20)
irisCluster <- kmeans(scaled_train_data[, 3:4], 3, nstart = 20)
irisCluster
irisCluster <- kmeans(scaled_train_data[, 3:4], 3, nstart = 20)
irisCluster
#-------------------------------------------------------
# to Analyze the performance
table(irisCluster$cluster, train_data$Species)
library(cluster)
clusplot(train_data[,3:4], irisCluster$cluster, main='2D representation of the Cluster solution',
color=TRUE, shade=TRUE,
labels=2, lines=0)
clusplot(train_data[,3:4], irisCluster$cluster, main='2D representation of the Cluster solution',
color=TRUE, shade=TRUE,
labels=2, lines=0)
wssplot <- function(data, nc=15, seed=1234){
wss <- (nrow(data)-1)*sum(apply(data,2,var))
for (i in 2:nc){
set.seed(seed)
wss[i] <- sum(kmeans(data, centers=i)$withinss)}
plot(1:nc, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")}
wssplot(scaled_train_data[, 3:4], nc=6)
wssplot(scaled_train_data[, 3:4], nc=20)
clusters <- function(x, centers) {
# compute squared euclidean distance from each sample to each cluster center
tmp <- sapply(seq_len(nrow(x)),
function(i) apply(centers, 1,
function(v) sum((x[i, ]-v)^2)))
#print(tmp)
max.col(-t(tmp))  # find index of min distance
}
clusters(scaled_test_data[, 3:4],irisCluster$centers)
table(test_data$Species,
clusters( scaled_test_data[, 3:4],irisCluster$centers) )
x=scaled_test_data[, 3:4]
centers= irisCluster$centers
tmp <- sapply(seq_len(nrow(x)),
function(i) apply(centers, 1,
function(v) sum((x[i, ]-v)^2)))
tmp
seq_len(nrow(x))
nrow(x)
t(tmp)
max.col(-t(tmp))
#to know center in same scale
aggregate(train_data[, 3:4], by=list(cluster=irisCluster$cluster), mean)
par(mfrow=c(2,2))
pie(colSums(iris[irisCluster$cluster==1,3:4]),cex=0.5)
pie(colSums(iris[irisCluster$cluster==2,3:4]),cex=0.5)
pie(colSums(iris[irisCluster$cluster==3,3:4]),cex=0.5)
par(mfrow=c(2,2))
pie(colSums(iris[irisCluster$cluster==1,3:4]),cex=0.5)
pie(colSums(iris[irisCluster$cluster==2,3:4]),cex=0.5)
pie(colSums(iris[irisCluster$cluster==3,3:4]),cex=0.5)
url = 'http://www.biz.uiowa.edu/faculty/jledolter/DataMining/protein.csv'
food <- read.csv(url)
url = 'http://www.biz.uiowa.edu/faculty/jledolter/DataMining/protein.csv'
food <- read.csv(url)
head(food)
#Missing value Treatment
titanic_data<- read.csv("D:/work/Shanu/ATI/Base_Analytics/class5/train.csv", stringsAsFactors = FALSE)
summary(titanic_data)
str(titanic_data)
colSums(is.na(titanic_data))
#to count number of NA's/ missing value
sum(is.na(kids))
#to count number of NA's/ missing value
sum(is.na(titanic_data))
#To calculate percentage missing values in each column
colSums(is.na(titanic_data))/nrow(titanic_data)
apply(titanic_data,2, function(x) sum(is.na(x)))
#Be careful with categorical missing data
unique(titanic_data$Cabin)
apply(titanic_data,2, function(x) sum(x==""))
apply(titanic_data,2, function(x) sum(x=="")/length(x))
#To remove all rows contains NA
titanic_data[complete.cases(titanic_data), ]
106+631
is.na(titanic_data$Age)
Mode <- function(x){
a = table(x) # x is a vector
return(names(a)[which.max(a)])
}
x=titanic_data$Embarked
a = table(x) # x is a vector
a
which.max(a)
names(a)[which.max(a)]
house_data<- read.csv("D:\\work\\Shanu\\ATI\\Base_Analytics\\class4\\Regression-Analysis-Data.csv")
remove_outliers <- function(x, na.rm = TRUE, ...) {
qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
H <- 1.5 * IQR(x, na.rm = na.rm)
y <- x
y[x < (qnt[1] - H)] <- NA
y[x > (qnt[2] + H)] <- NA
y
}
library(dplyr)
numeric_columns= colnames(select_if(house_data,is.numeric))
numeric_columns
numeric_columns
numeric_columns= colnames(select_if(house_data,is.numeric))
numeric_columns
x=house_data[,"House_Price"]
x
quantile(x, probs=c(.25, .75), na.rm = TRUE)
IQR(x, na.rm = TRUE)
H <- 1.5 * IQR(x, na.rm = TRUE)
y <- x
remove_outliers <- function(x, na.rm = TRUE) {
qnt <- quantile(x, probs=c(.25, .75), na.rm = TRUE)
H <- 1.5 * IQR(x, na.rm = TRUE)
y <- x
y[x < (qnt[1] - H)] <- NA
y[x > (qnt[2] + H)] <- NA
return(y)
}
apply(house_data[,numeric_columns], 2, function(x) sum(is.na(remove_outliers(x))))
